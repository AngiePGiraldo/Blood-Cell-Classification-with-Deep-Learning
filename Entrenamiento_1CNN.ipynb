{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a88c406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9957 images belonging to 4 classes.\n",
      "Found 2487 images belonging to 4 classes.\n",
      "Epoch 1/20\n",
      "312/312 [==============================] - 244s 779ms/step - loss: 1.4034 - accuracy: 0.2492 - val_loss: 1.3863 - val_accuracy: 0.2481\n",
      "Epoch 2/20\n",
      "312/312 [==============================] - 194s 623ms/step - loss: 1.3866 - accuracy: 0.2383 - val_loss: 1.3864 - val_accuracy: 0.2493\n",
      "Epoch 3/20\n",
      "312/312 [==============================] - 374s 1s/step - loss: 1.3865 - accuracy: 0.2484 - val_loss: 1.3863 - val_accuracy: 0.2509\n",
      "Epoch 4/20\n",
      "312/312 [==============================] - 504s 2s/step - loss: 1.3865 - accuracy: 0.2480 - val_loss: 1.3863 - val_accuracy: 0.2509\n",
      "Epoch 5/20\n",
      "312/312 [==============================] - 563s 2s/step - loss: 1.3865 - accuracy: 0.2420 - val_loss: 1.3863 - val_accuracy: 0.2505\n",
      "Epoch 6/20\n",
      "312/312 [==============================] - 484s 2s/step - loss: 1.3865 - accuracy: 0.2456 - val_loss: 1.3863 - val_accuracy: 0.2509\n",
      "Epoch 7/20\n",
      "312/312 [==============================] - 538s 2s/step - loss: 1.3865 - accuracy: 0.2479 - val_loss: 1.3863 - val_accuracy: 0.2509\n",
      "Epoch 8/20\n",
      "312/312 [==============================] - 605s 2s/step - loss: 1.3864 - accuracy: 0.2466 - val_loss: 1.3863 - val_accuracy: 0.2509\n",
      "Epoch 9/20\n",
      "312/312 [==============================] - 572s 2s/step - loss: 1.3864 - accuracy: 0.2506 - val_loss: 1.3863 - val_accuracy: 0.2509\n",
      "Epoch 10/20\n",
      "312/312 [==============================] - 668s 2s/step - loss: 1.3864 - accuracy: 0.2519 - val_loss: 1.3863 - val_accuracy: 0.2509\n",
      "Epoch 11/20\n",
      "312/312 [==============================] - 650s 2s/step - loss: 1.3864 - accuracy: 0.2510 - val_loss: 1.3863 - val_accuracy: 0.2509\n",
      "Epoch 12/20\n",
      "312/312 [==============================] - 408s 1s/step - loss: 1.3864 - accuracy: 0.2418 - val_loss: 1.3863 - val_accuracy: 0.2509\n",
      "Epoch 13/20\n",
      "312/312 [==============================] - 574s 2s/step - loss: 1.3864 - accuracy: 0.2527 - val_loss: 1.3863 - val_accuracy: 0.2505\n",
      "Epoch 14/20\n",
      "312/312 [==============================] - 612s 2s/step - loss: 1.3864 - accuracy: 0.2451 - val_loss: 1.3863 - val_accuracy: 0.2505\n",
      "Epoch 15/20\n",
      "312/312 [==============================] - 967s 3s/step - loss: 1.3864 - accuracy: 0.2433 - val_loss: 1.3863 - val_accuracy: 0.2505\n",
      "Epoch 16/20\n",
      "312/312 [==============================] - 616s 2s/step - loss: 1.3864 - accuracy: 0.2488 - val_loss: 1.3863 - val_accuracy: 0.2505\n",
      "Epoch 17/20\n",
      "312/312 [==============================] - 237s 752ms/step - loss: 1.3864 - accuracy: 0.2448 - val_loss: 1.3863 - val_accuracy: 0.2505\n",
      "Epoch 18/20\n",
      "312/312 [==============================] - 175s 562ms/step - loss: 1.3865 - accuracy: 0.2475 - val_loss: 1.3863 - val_accuracy: 0.2501\n",
      "Epoch 19/20\n",
      "312/312 [==============================] - 304s 974ms/step - loss: 1.3865 - accuracy: 0.2491 - val_loss: 1.3863 - val_accuracy: 0.2509\n",
      "Epoch 20/20\n",
      "312/312 [==============================] - 286s 913ms/step - loss: 1.3882 - accuracy: 0.2524 - val_loss: 1.3868 - val_accuracy: 0.2505\n",
      "78/78 [==============================] - 17s 219ms/step - loss: 1.3868 - accuracy: 0.2505\n",
      "Precisión: 25.050261616706848%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "# Define hiperparámetros\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "input_shape = (128, 128, 3)  # Ajusta las dimensiones según tus imágenes\n",
    "num_classes = 4  # Para los cuatro tipos de células sanguíneas\n",
    "\n",
    "# Crear el modelo de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Data augmentation (aumento de datos) para mejorar el rendimiento\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Cargar el conjunto de datos (asegúrate de tener tus imágenes en las carpetas correctas)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    'C:/Users/paola/OneDrive/Escritorio/parcial2Dl/images/TRAIN',  # Ruta al conjunto de entrenamiento\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    'C:/Users/paola/OneDrive/Escritorio/parcial2Dl/images/TEST',  # Ruta al conjunto de prueba\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_generator))\n",
    "\n",
    "# Evaluar el modelo\n",
    "score = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print(f'Precisión: {score[1]*100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71026ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
